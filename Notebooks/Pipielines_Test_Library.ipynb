{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines Test Library Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import piplines\n",
    "\n",
    "from binary_nets import binary_nets_wrapper # this is actually pipeline1\n",
    "from pipeline2 import pipeline2\n",
    "from pipeline3 import pipeline3\n",
    "from pipeline4 import pipeline4\n",
    "\n",
    "from ensemble_builder import ensemble_builder\n",
    "\n",
    "#Import datasets\n",
    "import dataset_generator as dataset\n",
    "\n",
    "from time import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(X_train_ocr, y_train_ocr, X_test_ocr, y_test_ocr, _) = dataset.generate_all_chars_with_class(verbose=0, plot=False)\n",
    "\n",
    "(X_train_cut, y_train_cut, X_test_cut, y_test_cut) = dataset.generate_dataset_for_segmentator(verbose=0, plot=False)\n",
    "\n",
    "\n",
    "X_train_char = {}\n",
    "y_train_char = {}\n",
    "X_test_char = {}\n",
    "y_test_char = {}\n",
    "\n",
    "for char in dataset.ALPHABET_ALL:\n",
    "    (X_train_char[char], y_train_char[char], X_test_char[char], y_test_char[char]) = dataset.generate_positive_and_negative_labeled(char, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting and training of the nets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path_b_nets = \"checkpoints/testpip/pipeline1\"\n",
    "\n",
    "# binary nets\n",
    "binary_nets = {}\n",
    "\n",
    "for letter in dataset.ALPHABET_ALL:\n",
    "    # Create the binary net\n",
    "    letter_path = os.path.join(path_b_nets, letter)\n",
    "    binary_nets[letter]= ensemble_builder(2, 2, number_of_nets=2, \\\n",
    "                path=letter_path, nb_filters1=20, nb_filters2=40, dense_layer_size1=150)\n",
    "    \n",
    "    # Training\n",
    "    binary_nets[letter].fit(X_train_char[letter], y_train_char[letter], X_test_char[letter], y_test_char[letter])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cut classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path_cut_classifier = \"checkpoints/testpip/cut_classifier\"\n",
    "\n",
    "cut_class = ensemble_builder(2, 2, number_of_nets=2,\\\n",
    "                 path=path_cut_classifier, nb_filters1=50, nb_filters2=100,\\\n",
    "                 dense_layer_size1=250)\n",
    "\n",
    "cut_class.fit(X_train_cut, y_train_cut, X_test_cut, y_test_cut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ocr classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path_ocr_class = \"checkpoints/testpip/ocr_classifier\"\n",
    "\n",
    "ocr_classifier = ensemble_builder(21+1, 2, number_of_nets=2, path=path_ocr_class,\\\n",
    "            nb_filters1=50, nb_filters2=100, dense_layer_size1=250)\n",
    "\n",
    "ocr_classifier.fit(X_train_ocr, y_train_ocr, X_test_ocr, y_test_ocr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pip1 = binary_nets_wrapper(binary_nets)\n",
    "\n",
    "prediction_pip1 = pip1.predict(X_test_ocr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Pipeline 2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pip2 = pipeline2(cut_class, ocr_classifier)\n",
    "\n",
    "prediction_pip2 = pip2.predict(X_test_ocr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pip3 = pipeline3(pip1, ocr_classifier)\n",
    "\n",
    "prediction_pip3 = pip3.predict(X_test_ocr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Pipeline 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pip4 = pipeline4(cut_class, pip1)\n",
    "\n",
    "prediction_pip4 = pip4.predict(X_test_ocr)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
