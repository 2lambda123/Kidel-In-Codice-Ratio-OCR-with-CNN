{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines Test Library Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import piplines\n",
    "from pipeline1 import pipeline1\n",
    "from pipeline2 import pipeline2\n",
    "from pipeline3 import pipeline3\n",
    "from pipeline4 import pipeline4\n",
    "\n",
    "#Import datasets\n",
    "import dataset_generator as dataset\n",
    "\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded test set for char 'a'\n",
      "Loaded test set for char 'c'\n",
      "Loaded test set for char 'd_mediana'\n",
      "Loaded test set for char 'e'\n",
      "Loaded test set for char 'i'\n",
      "Loaded test set for char 'm'\n",
      "Loaded test set for char 'n'\n",
      "Loaded test set for char 'o'\n",
      "Loaded test set for char 'r'\n",
      "Loaded test set for char 's_mediana'\n",
      "Loaded test set for char 't'\n",
      "Loaded test set for char 'u'\n",
      "Loaded test set for char 'd_alta'\n",
      "Loaded test set for char 's_alta'\n",
      "Loaded test set for char 'b'\n",
      "Loaded test set for char 'f'\n",
      "Loaded test set for char 'h'\n",
      "Loaded test set for char 'l'\n",
      "Loaded test set for char 'g'\n",
      "Loaded test set for char 'p'\n",
      "Loaded test set for char 'q'\n",
      "Loaded test set for char 's_bassa'\n"
     ]
    }
   ],
   "source": [
    "(X_train_ocr, y_train_ocr, X_test_ocr, y_test_ocr, _) = dataset.generate_all_chars_with_class(verbose=0, plot=False)\n",
    "\n",
    "(X_train_cut, y_train_cut, X_test_cut, y_test_cut) = dataset.generate_dataset_for_segmentator(verbose=0, plot=False)\n",
    "\n",
    "\n",
    "X_train_char = {}\n",
    "y_train_char = {}\n",
    "X_test_char = {}\n",
    "y_test_char = {}\n",
    "\n",
    "for char in dataset.ALPHABET_ALL:\n",
    "    (X_train_char[char], y_train_char[char], X_test_char[char], y_test_char[char]) = dataset.generate_positive_and_negative_labeled(char, verbose=0)\n",
    "    print (\"Loaded test set for char '\" + char + \"'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Pipelines for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pip1 = pipeline1(nb_epochs = 2, batch_size=512, path=\"checkpoints/testpip/pipeline1\", number_of_nets=2)\n",
    "\n",
    "pip2 = pipeline2(nb_epochs_ocr = 2, nb_epochs_cut_classifier=2, batch_size=512, \\\n",
    "                      path_ocr=\"checkpoints/testpip/pipeline2\",\\\n",
    "                      path_cut_classifier=\"checkpoints/testpip/cut_classifier\",\\\n",
    "                      number_of_nets_ocr=2, number_of_nets_cut_classifier=2)\n",
    "\n",
    "pip3 = pipeline3(nb_epochs_ocr = 2, nb_epochs_cut_classifier=2, batch_size=512,\\\n",
    "                      path_ocr=\"checkpoints/testpip/pipeline3\",\\\n",
    "                      path_cut_classifier=\"checkpoints/testpip/pipeline1\",\\\n",
    "                      number_of_nets_ocr=2, number_of_nets_cut_classifier=2) \n",
    "\n",
    "pip4 = pipeline4(nb_epochs_pip1 = 2, nb_epochs_cut_classifier=2, batch_size=512,\\\n",
    "                      path_cut_classifier=\"checkpoints/testpip/cut_classifier\", \\\n",
    "                      path_pipeline1=\"checkpoints/testpip/pipeline1\",\\\n",
    "                      number_of_nets_pip1=2, number_of_nets_cut_classifier=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training piplines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pipeline1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for letter in dataset.ALPHABET_ALL:\n",
    "    pip1.fit_letter(letter, X_train_char[letter], y_train_char[letter], X_test_char[letter], y_test_char[letter])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pipeline2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 0 ...\n",
      "Older Neural Net could not be found, creating a new net...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Older Neural Net could not be found, creating a new net...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip2.fit_cut_classifier(X_train_cut, y_train_cut, X_test_cut, y_test_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 0 ...\n",
      "Older Neural Net could not be found, creating a new net...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Older Neural Net could not be found, creating a new net...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip2.fit_ocr_net(X_train_ocr, y_train_ocr, X_test_ocr, y_test_ocr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pipeline3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 0 ...\n",
      "Older Neural Net could not be found, creating a new net...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Older Neural Net could not be found, creating a new net...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip3.fit_ocr_net(X_train_ocr, y_train_ocr, X_test_ocr, y_test_ocr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for letter in dataset.ALPHABET_ALL:\n",
    "    pip3.fit_letter_cut_classifier(letter, X_train_char[letter], y_train_char[letter], X_test_char[letter], y_test_char[letter])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pipeline4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n",
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for letter in dataset.ALPHABET_ALL:\n",
    "    pip4.fit_letter_pipeline1(letter, X_train_char[letter], y_train_char[letter], X_test_char[letter], y_test_char[letter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 0 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Training model 1 ...\n",
      "Not pre-processing 1 epoch(s)\n",
      "Done.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip4.fit_cut_classifier(X_train_cut, y_train_cut, X_test_cut, y_test_cut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load properly trained pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pt_pipeline1 = pipeline1(batch_size=512, path=\"checkpoints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pt_pipeline2 = pipeline2(batch_size=512, path_ocr=\"checkpoints/09_22-classes\",\\\n",
    "                        path_cut_classifier=\"checkpoints/letter_not_letter\",\\\n",
    "                        nb_filters1_cut=50, nb_filters2_cut=100, nb_filters1_ocr=50, nb_filters2_ocr=100 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pt_pipeline3 = pipeline3(batch_size=512, path_ocr=\"checkpoints/09_22-classes\",\\\n",
    "                      path_cut_classifier=\"checkpoints\",\\\n",
    "                      nb_filters1_cut=20, nb_filters2_cut=40, nb_filters1_ocr=50, nb_filters2_ocr=100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pt_pipeline4 = pipeline4(batch_size=512, path_cut_classifier=\"checkpoints/letter_not_letter\",\\\n",
    "                       path_pipeline1=\"checkpoints\", \\\n",
    "                       nb_filters1_cut=50, nb_filters2_cut=100, nb_filters1_pip=20, nb_filters2_pip=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict data with properly trained pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pipeline1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pipeline predicted  40.76 letter(s) per second\n"
     ]
    }
   ],
   "source": [
    "ctime = time()\n",
    "predpip1 = pt_pipeline1.predict(X_test_ocr)\n",
    "print(\"The pipeline predicted  %.2f letter(s) per second\" %(len(X_test_ocr)/(time()-ctime)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pipeline2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pipeline predicted 366.49 letter(s) per second\n"
     ]
    }
   ],
   "source": [
    "ctime = time()\n",
    "predpip2 = pt_pipeline2.predict(X_test_ocr)\n",
    "print(\"The pipeline predicted %.2f letter(s) per second\" %(len(X_test_ocr)/(time()-ctime)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pipeline3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pipeline predicted 36.66 letter(s) per second\n"
     ]
    }
   ],
   "source": [
    "ctime = time()\n",
    "predpip3 = pt_pipeline3.predict(X_test_ocr)\n",
    "print(\"The pipeline predicted %.2f letter(s) per second\" %(len(X_test_ocr)/(time()-ctime)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pipeline4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pipeline predicted 38.00 letter(s) per second\n"
     ]
    }
   ],
   "source": [
    "ctime = time()\n",
    "predpip4 = pt_pipeline4.predict(X_test_ocr)\n",
    "print(\"The pipeline predicted %.2f letter(s) per second\" %(len(X_test_ocr)/(time()-ctime)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pipeline1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pipeline scored a precision of 0.8716\n"
     ]
    }
   ],
   "source": [
    "precision1 = pt_pipeline1.evaluate(X_test_ocr, y_test_ocr)\n",
    "print(\"The pipeline scored a precision of %.4f\" %(precision1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pipeline2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pipeline scored a precision of 0.9616\n"
     ]
    }
   ],
   "source": [
    "precision2 = pt_pipeline2.evaluate(X_test_ocr, y_test_ocr)\n",
    "print(\"The pipeline scored a precision of %.4f\" %(precision2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pipeline3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pipeline scored a precision of 0.9609\n"
     ]
    }
   ],
   "source": [
    "precision3 = pt_pipeline3.evaluate(X_test_ocr, y_test_ocr)\n",
    "print(\"The pipeline scored a precision of %.4f\" %(precision3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pipeline4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pipeline scored a precision of 0.8704\n"
     ]
    }
   ],
   "source": [
    "precision4 = pt_pipeline4.evaluate(X_test_ocr, y_test_ocr)\n",
    "print(\"The pipeline scored a precision of %.4f\" %(precision4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The evaluation does not keep count of bad cuts, it simply ignores it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
